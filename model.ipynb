{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733afa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations\n",
    "import seaborn as sns  # For statistical data visualization based on Matplotlib\n",
    "from tabulate import tabulate  # For pretty-printing tabular data\n",
    "\n",
    "from sklearn import metrics  # For model evaluation metrics\n",
    "from sklearn.ensemble import RandomForestClassifier  # For building a random forest classifier\n",
    "from sklearn.model_selection import train_test_split  # To split data into train and test sets\n",
    "from sklearn.metrics import recall_score  # To calculate recall score for classification models\n",
    "from sklearn.metrics import classification_report  # To generate classification performance report\n",
    "from sklearn.metrics import confusion_matrix  # To create a confusion matrix for model evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier  # For building a Decision Tree classifier\n",
    "from imblearn.combine import SMOTEENN  # For handling class imbalance using SMOTE and ENN\n",
    "import pickle # For storing and loading Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bed522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV file\n",
    "df = pd.read_csv(r\"D:\\Stuff\\Data Science\\Machine Learning Models\\Customer_churn_model\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5aa8b4",
   "metadata": {},
   "source": [
    "##### As it is obsererved in the EDA part \n",
    "- It is observed that `TotalCharges` is of type **object**, whereas it should be of type **float**.\n",
    "- The `SeniorCitizen` column should ideally be of type **object** instead of **int64**, since it contains values `0` and `1`, which represent categories rather than numerical values. Changing the data type helps reduce confusion during calculations.\n",
    "- All other column data types appear to be appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' column to numeric, coercing errors to NaN\n",
    "df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')\n",
    "# Convert 'SSeniorCitizen' column to categorical type\n",
    "df.SeniorCitizen = df.SeniorCitizen.astype('category')\n",
    "# Display the data types of each column again to confirm changes \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e4824",
   "metadata": {},
   "source": [
    "#### It is observed that the 'TotalCharges' column has some NaN values.( In EDA File )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b491a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in any column\n",
    "df.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ca440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to avoid modifying the original\n",
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tenure group labels in 12-month intervals (e.g., '1 - 12', '13 - 24', ...)\n",
    "labels = [\"{0} - {1}\".format(i, i + 11) for i in range(1, 72, 12)]\n",
    "\n",
    "# Categorize 'tenure' into discrete bins using the defined intervals\n",
    "# right=False → interval includes the left value and excludes the right (e.g., [1,13) )\n",
    "new_df['tenure_group'] = pd.cut(new_df.tenure, bins=range(1, 80, 12), right=False, labels=labels)\n",
    "\n",
    "# Display the distribution of customers across tenure groups\n",
    "new_df['tenure_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'tenure' and 'customerID' columns from the DataFrame \n",
    "new_df.drop(columns = ['customerID','tenure'], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to churn column\n",
    "new_df['Churn'] = np.where(new_df['Churn']=='Yes',1,0)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03806050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplly label encoding to categorical columns\n",
    "new_df_dummies = pd.get_dummies(new_df)\n",
    "new_df_dummies = new_df_dummies.astype(int)\n",
    "new_df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb28a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'Churn' column to use all other columns as features\n",
    "x = new_df_dummies.drop(columns = 'Churn',axis = 1)\n",
    "\n",
    "# Extracting the 'Churn' column as the target variable\n",
    "y = new_df_dummies['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the feature set and target variable\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6b22d",
   "metadata": {},
   "source": [
    "##### Split test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets with a 70-30 split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cba98c",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a DecisionTreeClassifier model\n",
    "model_dt = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=6, min_samples_leaf=8)\n",
    "\n",
    "# - criterion=\"gini\": The Gini impurity measure is used to split nodes.\n",
    "# - random_state=42: Ensures reproducibility of results.\n",
    "# - max_depth=6: Limits the depth of the tree to prevent overfitting.\n",
    "# - min_samples_leaf=8: Ensures each leaf node has at least 8 samples to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f816375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the DecisionTreeClassifier model to the training data\n",
    "model_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59307ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the trained DecisionTreeClassifier model on the test data (x_test)\n",
    "y_pred = model_dt.predict(x_test)\n",
    "print(f\"Total Rows: {y_pred.shape[0]}\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy on the test set\n",
    "print(f\"Accuracy: {(model_dt.score(x_test, y_test))*100 :.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_classification_report(y_true, y_pred, labels=None):\n",
    "    report = classification_report(y_true, y_pred, labels=labels)\n",
    "    print(\"-\" * 60)\n",
    "    print(report)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Display precision, recall, f1-score, and support for each class (0: No Churn, 1: Churn)\n",
    "print(classification_report(y_test, y_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ecd92",
   "metadata": {},
   "source": [
    "### Model Evaluation Insight\n",
    "\n",
    "As you can see, the **accuracy** is relatively low. Since this is an **imbalanced dataset**, we shouldn't rely on accuracy as a performance metric. Accuracy can be misleading in such cases — it's often considered **\"cursed\"** when class distributions are skewed.\n",
    "\n",
    "#### What should we focus on instead?\n",
    "We need to evaluate the model using:\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-score**\n",
    "\n",
    "Especially for the **minority class (Class 1: Churned customers)**.\n",
    "\n",
    "#### Observation:\n",
    "- Precision, recall, and F1-score for churned customers are significantly low.\n",
    "- This indicates the model is not effectively capturing the patterns related to customer churn.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Step: Apply SMOTEENN\n",
    "We'll now move ahead to apply **SMOTEENN**, a technique that combines:\n",
    "- **SMOTE (Synthetic Minority Oversampling Technique)** to balance the minority class, and\n",
    "- **ENN (Edited Nearest Neighbors)** to clean noisy samples\n",
    "\n",
    "This should help improve model performance on the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTEENN to balance the dataset by oversampling the minority class and cleaning noisy samples\n",
    "sm = SMOTEENN()\n",
    "x_smot, y_smot = sm.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the resampled data into training and testing sets (80/20 split)\n",
    "xr_train, xr_test, yr_train, yr_test = train_test_split(x_smot, y_smot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b70502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree with specified hyperparameters on SMOTEENN data\n",
    "model_dt_smote = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=6, min_samples_leaf=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Decision Tree model on the resampled training data\n",
    "model_dt_smote.fit(xr_train, yr_train)\n",
    "\n",
    "# Predict on the test set\n",
    "yr_predict = model_dt_smote.predict(xr_test)\n",
    "\n",
    "# Get accuracy score on resampled test data\n",
    "model_score_r = model_dt_smote.score(xr_test, yr_test)\n",
    "print(f\"Model Score: {model_score_r:.2%}\")\n",
    "\n",
    "# Display classification report for precision, recall, f1-score\n",
    "print(metrics.classification_report(yr_test, yr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcca926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(yr_test, yr_predict)\n",
    "\n",
    "# Plot it using seaborn\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Churn\", \"Churn\"], yticklabels=[\"No Churn\", \"Churn\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the confusion matrix for the resampled test set\n",
    "print(\"confusion_matrix: \",\"\\n\",metrics.confusion_matrix(yr_test, yr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dca71",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1019eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Random Forest classifier with 100 trees, Gini index for splitting, and specific hyperparameters\n",
    "model_rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Random Forest model to the training data\n",
    "model_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target labels using the trained Random Forest model on the test data\n",
    "y_pred = model_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the Random Forest model on the test data\n",
    "print(f\"Random forest Model Score: {model_rf.score(x_test, y_test):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5411fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display the classification report for the Random Forest model's predictions\n",
    "print(classification_report(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103acac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTEENN (Synthetic Minority Over-sampling Technique + Edited Nearest Neighbors) to balance the dataset by generating synthetic samples and removing noise\n",
    "x_smot1, y_smot1 = sm.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the resampled dataset with 80% for training and 20% for testing\n",
    "xrf_train, xrf_test, yrf_train, yrf_test = train_test_split(x_smot1, y_smot1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87453fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a RandomForestClassifier model with specified parameters\n",
    "model_rf_smote = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)\n",
    "\n",
    "# - 100 trees (n_estimators=100)\n",
    "# - Gini impurity for splitting (criterion='gini')\n",
    "# - Random state set to 100 for reproducibility\n",
    "# - Maximum depth of the trees set to 6 (max_depth=6)\n",
    "# - Minimum samples per leaf set to 8 (min_samples_leaf=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d223a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Random Forest model on the resampled training data\n",
    "model_rf_smote.fit(xrf_train, yrf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable using the trained Random Forest model\n",
    "yr_predict1 = model_rf_smote.predict(xrf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance by calculating the accuracy on the resampled test set\n",
    "model_score_r1 = model_rf_smote.score(xrf_test, yrf_test)\n",
    "print(f\"Random Forest Model Score: {model_score_r1:.2%}\") # Print the model's accuracy score on the resampled test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report to evaluate precision, recall, f1-score, etc., for each class\n",
    "print(metrics.classification_report(yrf_test, yr_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrix to evaluate the performance of the model on the resampled test set\n",
    "print(metrics.confusion_matrix(yrf_test, yr_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb03e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "cm1 = confusion_matrix(yrf_test, yr_predict1)\n",
    "\n",
    "# Plot it using seaborn\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Churn\", \"Churn\"], yticklabels=[\"No Churn\", \"Churn\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the confusion matrix for the resampled test set\n",
    "print(\"confusion_matrix: \",\"\\n\",metrics.confusion_matrix(yrf_test, yr_predict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413b69f",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained Random Forest model with SMOTEENN applied to a file using pickle\n",
    "# filename = 'churn.model'\n",
    "# # filename = 'model.sav' # Define the filename for saving the model\n",
    "# pickle.dump(model_rf_smote, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542e001",
   "metadata": {},
   "source": [
    "##### Open loaded Model to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6640dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the previously saved Random Forest model from the file\n",
    "# load_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# # Evaluate the loaded model's performance on the test data\n",
    "# print(f\"Model Score: {load_model.score(xrf_test, yrf_test):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3a55b",
   "metadata": {},
   "source": [
    "**Our final model, i.e., the RF Classifier with SMOTEENN, is now ready and saved in the file `churn.model`. We will use this model to prepare APIs, enabling us to access it from the UI.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Separate features and target\n",
    "# X = new_df.drop('Churn', axis=1)\n",
    "# y = new_df['Churn']  # Already encoded as 1/0\n",
    "\n",
    "# # Identify categorical and numeric columns\n",
    "# cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "# num_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "# # Build preprocessing pipeline\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('cat', OneHotEncoder(drop='first'), cat_cols),  # drop='first' to avoid dummy trap\n",
    "#     ('num', 'passthrough', num_cols)\n",
    "# ])\n",
    "\n",
    "# # Combine preprocessing + model in a full pipeline\n",
    "# clf_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('classifier', RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Fit the pipeline\n",
    "# clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on new data\n",
    "# y_pred = clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# import joblib\n",
    "\n",
    "# # Assuming you already trained your model/pipeline\n",
    "# pipe = Pipeline([\n",
    "#     ('clf', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# pipe.fit(xr_train1, yr_train1)\n",
    "\n",
    "# # Save it\n",
    "# joblib.dump(pipe, 'model.sav')\n",
    "# print(\"✅ Model saved successfully!\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# model = joblib.load('model.sav')\n",
    "# print(type(model))  # It should be <class 'sklearn.ensemble.RandomForestClassifier'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
